"""
Chat with PDF using LlamaIndex, Couchbase SearchVectorStore & OpenAI
This version uses CouchbaseSearchVectorStore for vector operations.

Relocated to FTS/ directory. Ensures parent directory is in sys.path so that
`shared` package imports continue to function when running this script directly.
"""
import os
import sys

# Ensure parent directory is on sys.path for `shared` imports when executed from here
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(CURRENT_DIR)
if PARENT_DIR not in sys.path:
    sys.path.insert(0, PARENT_DIR)

import streamlit as st
from llama_index.core import StorageContext
from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore

from shared.config import (
    setup_authentication,
    get_environment_variables,
    validate_environment_variables,
    get_prompts,
)
from shared.common import (
    store_document,
    connect_to_couchbase,
    setup_llm_and_embeddings,
    create_pure_llm_chat_engine,
    setup_sidebar_content,
    initialize_session_state,
    handle_chat_interaction,
)


@st.cache_resource()
def get_search_vector_store(
    _cluster,
    db_bucket,
    db_scope,
    db_collection,
    index_name,
):
    """Return the Couchbase SearchVectorStore."""
    return CouchbaseSearchVectorStore(
        cluster=_cluster,
        bucket_name=db_bucket,
        scope_name=db_scope,
        collection_name=db_collection,
        index_name=index_name,
    )


def main():
    """Main application function"""
    st.set_page_config(
        page_title="Chat with your PDF using LlamaIndex, Couchbase SearchVectorStore & OpenAI",
        page_icon="üîç",
        layout="centered",
        initial_sidebar_state="auto",
        menu_items=None,
    )

    # Authentication
    if not setup_authentication():
        return

    # Load and validate environment variables
    validate_environment_variables()
    env_vars = get_environment_variables()

    # Connect to Couchbase Vector Store
    cluster = connect_to_couchbase(
        env_vars['DB_CONN_STR'],
        env_vars['DB_USERNAME'],
        env_vars['DB_PASSWORD']
    )

    vector_store = get_search_vector_store(
        cluster,
        env_vars['DB_BUCKET'],
        env_vars['DB_SCOPE'],
        env_vars['DB_COLLECTION'],
        env_vars['INDEX_NAME'],
    )

    # Get prompt templates
    template_rag, template_without_rag = get_prompts()

    # Frontend
    couchbase_logo = "https://emoji.slack-edge.com/T024FJS4M/couchbase/4a361e948b15ed91.png"

    st.title("Chat with PDF (SearchVectorStore)")
    st.markdown(
        "üîç **SearchVectorStore Version** - Answers with [Couchbase logo](https://emoji.slack-edge.com/T024FJS4M/couchbase/4a361e948b15ed91.png) are generated using *RAG* while ü§ñÔ∏è are generated by pure *LLM (ChatGPT)*"
    )

    # Setup LLM and embeddings
    llm, embeddings = setup_llm_and_embeddings()
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    # Pure LLM for comparison of results
    st.session_state.chat_llm = create_pure_llm_chat_engine(template_without_rag)

    with st.sidebar:
        st.header("Upload your PDF")
        with st.form("upload pdf"):
            uploaded_file = st.file_uploader(
                "Choose a PDF.",
                help="The document will be deleted after one hour of inactivity (TTL).",
                type="pdf",
            )
            submitted = st.form_submit_button("Upload")
            if submitted:
                index = store_document(uploaded_file, storage_context)
                if not index:
                    st.warning("Please upload a valid PDF")
                else:
                    # Create the chat engine with context from the uploaded data
                    st.session_state.chat_engine_rag = index.as_chat_engine(
                        chat_mode="context",
                        llm=llm,
                        system_prompt=template_rag,
                    )

        setup_sidebar_content()

    # Initialize session state
    initialize_session_state()

    # Handle chat interaction
    handle_chat_interaction(couchbase_logo)


if __name__ == "__main__":
    main()
